---
layout: post
title: "å›¾åƒè‡ªå›å½’ç”Ÿæˆæ¨¡å‹PixelCNN"
date: 2025-04-08 09:00:00 +0800
categories: ç ”ç©¶ç”Ÿæ¶¯
tag: Autoregressive

---

PixelCNN æ˜¯ä¸€ä¸ªéå¸¸æœ‰ä»£è¡¨æ€§çš„ **å›¾åƒè‡ªå›å½’ç”Ÿæˆæ¨¡å‹**ï¼Œå®ƒå¯ä»¥é€åƒç´ åœ°ç”Ÿæˆå›¾åƒï¼Œå°¤å…¶æ˜¯ç”¨äºå»ºæ¨¡åƒç´ ä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚

<!-- more -->

# å›¾åƒè‡ªå›å½’ç”Ÿæˆæ¨¡å‹PixelCNN



------

## ğŸ§± PixelCNNï¼šåŸºæœ¬æ€æƒ³

### âœ… æ ¸å¿ƒæ¦‚å¿µï¼š

> å°†ä¸€å¼ å›¾åƒçœ‹ä½œä¸€ä¸ªåƒç´ åºåˆ—ï¼ŒæŒ‰ä»å·¦åˆ°å³ã€ä»ä¸Šåˆ°ä¸‹çš„é¡ºåºé€åƒç´ å»ºæ¨¡ï¼Œ
>  æ¯ä¸€ä¸ªåƒç´ ç‚¹ $x_{i,j}$ çš„ç”Ÿæˆéƒ½ä¾èµ–äºå…¶**å·¦è¾¹å’Œä¸Šè¾¹çš„åƒç´ **ã€‚

------

## ğŸ“ æ•°å­¦å»ºæ¨¡æ–¹å¼

å¯¹ä¸€å¼  $n \times n$ çš„å›¾åƒï¼ŒPixelCNN å»ºæ¨¡å®ƒçš„è”åˆåˆ†å¸ƒï¼š
$$
P(\mathbf{x}) = \prod_{i=1}^n \prod_{j=1}^n P(x_{i,j} \mid x_{<i,j})
$$
å…¶ä¸­ $x_{<i,j}$ è¡¨ç¤ºæ‰€æœ‰åœ¨ $(i,j)$ ä¹‹å‰çš„åƒç´ ï¼ˆé€šå¸¸æ˜¯å·¦ä¾§å’Œä¸Šæ–¹ï¼‰ã€‚

------

## ğŸ§  ç»“æ„ç»†èŠ‚

### 1. **Masked Convolutionï¼ˆæ©ç å·ç§¯ï¼‰**

- ä¸ºäº†ä¿è¯åƒç´  $x_{i,j}$ **åªèƒ½çœ‹åˆ°å®ƒä¹‹å‰çš„åƒç´ **ï¼ŒPixelCNN ä½¿ç”¨äº†ç‰¹åˆ¶çš„å·ç§¯æ ¸ï¼Œç§°ä¸º **æ©ç å·ç§¯**ã€‚
- ä¸¤ç§æ©ç ï¼š
  - **Mask A**ï¼šç”¨äºç¬¬ä¸€å±‚ï¼Œå®Œå…¨é¿å…â€œçœ‹è§å½“å‰åƒç´ â€
  - **Mask B**ï¼šç”¨äºåç»­å±‚ï¼Œå¯ä»¥â€œçœ‹åˆ°å½“å‰åƒç´ çš„é€šé“ä¹‹é—´â€

> ğŸ›¡ï¸ è¿™æ˜¯ä¸ºäº†è§£å†³ä¿¡æ¯æ³„éœ²é—®é¢˜ï¼ˆä¸èƒ½æå‰çœ‹åˆ°è¦é¢„æµ‹çš„åƒç´ ï¼‰

------

### 2. **é€šé“å»ºæ¨¡ï¼ˆRGBï¼‰**

- æ¯ä¸ªåƒç´ åŒ…å«å¤šä¸ªé€šé“ï¼ˆRã€Gã€Bï¼‰
- åƒç´ å†…éƒ¨é¡ºåºå»ºæ¨¡ï¼šå…ˆç”Ÿæˆ Rï¼Œç„¶å Gï¼Œæœ€å Bï¼Œæ¯ä¸ªéƒ½ä¾èµ–å‰é¢ä¿¡æ¯

------

### 3. **è¾“å‡ºåˆ†å¸ƒ**

- å¯¹æ¯ä¸ªåƒç´ ï¼Œè¾“å‡ºçš„æ˜¯ **ç¦»æ•£åˆ†å¸ƒ**ï¼ˆä¾‹å¦‚ 256 ä¸ªå€¼ï¼‰
- é€šå¸¸ç”¨ Softmax å¯¹æ¯ä¸ªé€šé“è¿›è¡Œå»ºæ¨¡

------

## ğŸ”„ é‡‡æ ·è¿‡ç¨‹ï¼ˆé€åƒç´ ç”Ÿæˆï¼‰

1. åˆå§‹åŒ–ä¸€ä¸ªç©ºå›¾åƒï¼ˆå…¨ä¸º 0 æˆ–éšæœºå€¼ï¼‰
2. æŒ‰ç…§ä»å·¦åˆ°å³ã€ä»ä¸Šåˆ°ä¸‹çš„é¡ºåºç”Ÿæˆæ¯ä¸ªåƒç´ 
3. æ¯æ¬¡å°†ç”Ÿæˆçš„åƒç´ ä½œä¸ºè¾“å…¥ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªåƒç´ 

------

## ğŸ§© PixelCNN çš„ä¼˜ç¼ºç‚¹

| ä¼˜ç‚¹ âœ…                        | ç¼ºç‚¹ âŒ                       |
| ----------------------------- | ---------------------------- |
| ç²¾ç¡®å»ºæ¨¡åƒç´ é—´ä¾èµ–å…³ç³»        | æ¨ç†é€Ÿåº¦æ…¢ï¼ˆé€åƒç´ ç”Ÿæˆï¼‰     |
| ç»“æ„ç®€å•ï¼Œå®¹æ˜“å®ç°            | é•¿è·ç¦»åƒç´ ä¾èµ–å»ºæ¨¡æœ‰é™       |
| ä¸éœ€è¦éšå˜é‡ï¼ˆå¦‚ VAE ä¸­çš„ zï¼‰ | å›¾åƒè´¨é‡ç›¸å¯¹è¾ƒå·®ï¼ˆæ—©æœŸç‰ˆæœ¬ï¼‰ |



------

## ğŸ§© 1. MaskedConv2dï¼ˆæ ¸å¿ƒæ©ç å·ç§¯ï¼‰

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class MaskedConv2d(nn.Conv2d):
    def __init__(self, mask_type, in_channels, out_channels, kernel_size, **kwargs):
        super().__init__(in_channels, out_channels, kernel_size, **kwargs)
        assert mask_type in ('A', 'B'), "mask_type must be 'A' or 'B'"
        self.register_buffer("mask", self.weight.data.clone())

        _, _, kH, kW = self.weight.size()
        self.mask.fill_(1)
        yc, xc = kH // 2, kW // 2
		
        self.mask[:, :, yc, xc + (mask_type == 'B'):] = 0
        self.mask[:, :, yc + 1:] = 0

    def forward(self, x):
        self.weight.data *= self.mask
        return super().forward(x)
```

### ğŸ‘† è¯´æ˜ï¼š

- **Mask A**ï¼šç”¨äºç¬¬ä¸€å±‚ï¼Œ**ä¸å…è®¸çœ‹åˆ°å½“å‰åƒç´ ç‚¹**ï¼Œ**å½“å‰åƒç´ ï¼ˆä¸­å¿ƒï¼‰** å’Œ **å³ä¾§åƒç´ ** å…¨éƒ¨å±è”½æ‰ï¼
- **Mask B**ï¼šç”¨äºåç»­å±‚ï¼Œåªå±è”½å³ä¾§åƒç´ ï¼Œä½†**ä¿ç•™ä¸­å¿ƒåƒç´ æœ¬èº«**

ä¸€ä¸ª 7x7 çš„å·ç§¯æ ¸è¢«æ©ç æˆè¿™æ ·ï¼ˆ1 å¯ç”¨ï¼Œ0 è¢«å±è”½ï¼‰ï¼š

```
1 1 1 1 1 1 1
1 1 1 1 1 1 1
1 1 1 1 1 1 1
1 1 1 0 0 0 0  â† ä¸­å¿ƒè¡Œï¼šå½“å‰åƒç´ å’Œå³è¾¹éƒ½å±è”½
0 0 0 0 0 0 0  â† ä¸‹æ–¹è¡Œå…¨å±è”½
0 0 0 0 0 0 0
0 0 0 0 0 0 0
```

------

## ğŸ—ï¸ 2. ç®€å• PixelCNN ç½‘ç»œç»“æ„

```python
class SimplePixelCNN(nn.Module):
    def __init__(self, input_channels=3, hidden_channels=64, num_layers=7):
        super().__init__()
        layers = []

        # ç¬¬ä¸€å±‚ä½¿ç”¨ Mask A
        layers.append(MaskedConv2d('A', input_channels, hidden_channels, kernel_size=7, padding=3))

        # åç»­å±‚ä½¿ç”¨ Mask B
        for _ in range(num_layers - 2):
            layers.append(nn.ReLU())
            layers.append(MaskedConv2d('B', hidden_channels, hidden_channels, kernel_size=7, padding=3))

        # æœ€åä¸€å±‚è¾“å‡ºæ¯ä¸ªé€šé“çš„ 256 ç»´ softmax logits
        layers.append(nn.ReLU())
        layers.append(nn.Conv2d(hidden_channels, input_channels * 256, kernel_size=1))

        self.net = nn.Sequential(*layers)

    def forward(self, x):
        out = self.net(x)
        # reshape: [B, 3*256, H, W] â†’ [B, 3, 256, H, W]
        B, C, H, W = out.shape
        out = out.view(B, 3, 256, H, W)
        return out
```

------

## ğŸ“¥ è¾“å…¥è¾“å‡ºè¯´æ˜

- è¾“å…¥ï¼š`x` æ˜¯ [B, 3, H, W] çš„å›¾åƒ tensorï¼Œåƒç´ å€¼é€šå¸¸æ˜¯ one-hot æˆ–ç¦»æ•£æ•´æ•°ã€‚
- è¾“å‡ºï¼šsoftmax logitsï¼ˆç”¨äºå¯¹æ¯ä¸ªåƒç´ ç‚¹æ¯ä¸ªé€šé“è¿›è¡Œåˆ†ç±»ï¼‰

------

## ğŸ§ª é‡‡æ ·æµç¨‹

```python
def sample_from_pixelcnn(model, image_shape, device='cuda'):
    model.eval()
    B, C, H, W = image_shape
    image = torch.zeros((B, C, H, W), dtype=torch.float32, device=device)

    with torch.no_grad():
        for i in range(H):
            for j in range(W):
                out = model(image)  # [B, 3, 256, H, W]
                probs = F.softmax(out[:, :, :, i, j], dim=-1)  # [B, 3, 256]
                pixel = torch.multinomial(probs.view(B * C, -1), 1).view(B, C).float() / 255.0
                image[:, :, i, j] = pixel

    return image
```

------

