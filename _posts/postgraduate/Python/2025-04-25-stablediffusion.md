---
layout: post
title: "Stable Diffusion æ¨¡å‹ç»“æ„"
date: 2025-04-25 09:00:00 +0800 
categories: ç ”ç©¶ç”Ÿæ¶¯
tag: diffusion
---



Stable Diffusion æ˜¯ä¸€ç§ **æ–‡æœ¬å¼•å¯¼çš„æ½œç©ºé—´æ‰©æ•£æ¨¡å‹ï¼ˆLatent Diffusion Model, LDMï¼‰**

<!-- more -->

## Stable Diffusion æ¨¡å‹ç»“æ„



Stable Diffusion æ˜¯ä¸€ç§ **æ–‡æœ¬å¼•å¯¼çš„æ½œç©ºé—´æ‰©æ•£æ¨¡å‹ï¼ˆLatent Diffusion Model, LDMï¼‰**ï¼Œå…¶æ ¸å¿ƒç»„ä»¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š

------

### 1. **Encoder / Decoderï¼ˆVAEï¼‰**

- å°†åŸå§‹å›¾åƒæ˜ å°„åˆ° **æ½œç©ºé—´ï¼ˆlatent spaceï¼‰**ï¼Œå¤§å¤§å‡å°‘äº†æ‰©æ•£è¿‡ç¨‹çš„è®¡ç®—å¼€é”€ã€‚
- ç¼–ç å™¨ï¼šå›¾åƒ â†’ æ½œåœ¨è¡¨ç¤º `z`
- è§£ç å™¨ï¼šæ½œåœ¨è¡¨ç¤º `z` â†’ å›¾åƒ

------

### 2. **UNetï¼ˆæ‰©æ•£æ¨¡å‹çš„æ ¸å¿ƒï¼‰**

- ç»“æ„ï¼šU-Net ç¼–ç å™¨-è§£ç å™¨æ¡†æ¶ï¼Œæ”¯æŒè·³è·ƒè¿æ¥ã€‚
- è¾“å…¥ï¼š
  - å™ªå£°å›¾åƒï¼ˆlatent `z_t`ï¼‰
  - æ—¶é—´æ­¥ `t`
  - æ–‡æœ¬æ¡ä»¶å‘é‡ï¼ˆæ¥è‡ª CLIP çš„æ–‡æœ¬åµŒå…¥ï¼‰

#### å­æ¨¡å—åŒ…æ‹¬ï¼š

- **ResNet å—**ï¼ˆå¸¦æ—¶é—´æ­¥ & æ¡ä»¶åµŒå…¥ï¼‰
- **Cross Attention**ï¼šç”¨äºèåˆæ–‡æœ¬æ¡ä»¶ï¼ˆCLIP ç¼–ç åçš„æ–‡æœ¬åµŒå…¥ï¼‰
- **Self-Attention**

> âœ… æ”¯æŒ Classifier-Free Guidance ä»¥æ§åˆ¶æ–‡æœ¬æ¡ä»¶å¯¹å›¾åƒç”Ÿæˆçš„å½±å“åŠ›ã€‚

- $\mathbf{x}_t$ï¼šå½“å‰æ‰©æ•£å›¾åƒï¼ˆlatentï¼‰
- $\mathbf{c}$ï¼šæ–‡æœ¬æ¡ä»¶ï¼ˆCLIP ç¼–ç å‘é‡ï¼‰
- $\epsilon_\theta(\mathbf{x}_t, t, \mathbf{c})$ï¼šUNet é¢„æµ‹çš„å™ªå£°ï¼ˆæœ‰æ¡ä»¶ï¼‰
- $\epsilon_\theta(\mathbf{x}_t, t, \emptyset)$ï¼šUNet é¢„æµ‹çš„å™ªå£°ï¼ˆæ— æ¡ä»¶ï¼‰
- $\mathbf{c} = \emptyset$ è¡¨ç¤ºæ²¡æœ‰è¾“å…¥æ¡ä»¶ï¼Œå³ unconditional åˆ†æ”¯ã€‚
- $s$ï¼šå¼•å¯¼ç³»æ•°ï¼ˆguidance scaleï¼‰

åˆ™ **æœ€ç»ˆä½¿ç”¨çš„é¢„æµ‹ä¸ºï¼š**
$$
\epsilon_{\text{guided}} = \epsilon_\theta(\mathbf{x}_t, t, \emptyset) + s \cdot \left( \epsilon_\theta(\mathbf{x}_t, t, \mathbf{c}) - \epsilon_\theta(\mathbf{x}_t, t, \emptyset) \right)
$$

> åœ¨å®é™…ä¸­ï¼Œ`s` é€šå¸¸è®¾ç½®ä¸º **7.5 ~ 12.0**ï¼Œè§†å…·ä½“åº”ç”¨è€Œå®šã€‚

------

### 3. **Text Encoderï¼ˆæ¡ä»¶éƒ¨åˆ†ï¼‰**

- é€šå¸¸ä½¿ç”¨ **CLIP çš„æ–‡æœ¬ç¼–ç å™¨**ï¼ˆ `CLIPTextModel`ï¼‰å°†æç¤ºè¯ï¼ˆpromptï¼‰è½¬åŒ–ä¸ºå‘é‡è¡¨ç¤ºã€‚
- è¾“å‡ºï¼šåµŒå…¥å‘é‡ç”¨äºè¾“å…¥ UNet ä¸­çš„ cross-attention æ¨¡å—ã€‚

------

### 4. **Diffusion Processï¼ˆæ‰©æ•£ä¸åæ‰©æ•£ï¼‰**

- å‰å‘æ‰©æ•£ï¼šé€æ­¥å‘æ½œåœ¨è¡¨ç¤º `z` æ·»åŠ å™ªå£°ã€‚
- åå‘è¿‡ç¨‹ï¼š
  - UNet é¢„æµ‹å™ªå£°
  - ä½¿ç”¨è°ƒåº¦å™¨ï¼ˆ DDIMã€DDPMï¼‰ä¸€æ­¥æ­¥å»å™ªã€‚

------

## ğŸ—‚ æ¨¡å‹ç»“æ„æµç¨‹å›¾

```
Text Prompt --â†’ CLIP Encoder --â†’ Text Embedding
                                     â†“
          +--------------------+     â†“
Image --> |   Encoder (VAE)    |     â†“
          |    â†“ latent z      |     â†“
          +--------------------+     â†“
                                     â†“
            +-----------------------------------------+
 z_t (latent) â†’ UNet(noise predictor) â† t, Text Embed |
            +-----------------------------------------+
                                     â†“
          +--------------------+
          |   Decoder (VAE)    | â†’ Output Image
          +--------------------+
```

------

## ğŸ§© æ€»ç»“

| æ¨¡å—         | åŠŸèƒ½                                |
| ------------ | ----------------------------------- |
| VAE ç¼–ç å™¨   | å›¾åƒ â†’ æ½œç©ºé—´ï¼ˆå‹ç¼©ï¼‰               |
| UNet         | åœ¨æ½œç©ºé—´ä¸­æ‰§è¡Œå»å™ªè¿‡ç¨‹              |
| Text Encoder | æä¾›æ¡ä»¶å¼•å¯¼ï¼ˆå¦‚ CLIPï¼‰             |
| Decoder      | æ½œåœ¨å›¾åƒé‡æ„å›åŸå§‹å›¾åƒ              |
| Diffusion    | æ·»åŠ /å»é™¤å™ªå£°ä»¥ç”Ÿæˆå›¾åƒï¼ˆé‡‡æ ·è¿‡ç¨‹ï¼‰ |



## å®ç°

[XinbeiCai/pytorch-stable-diffusion](https://github.com/XinbeiCai/pytorch-stable-diffusion)